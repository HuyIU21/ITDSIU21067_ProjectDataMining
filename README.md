# ITDSIU21067_ProjectDataMining

Overview
This project focuses on evaluating several machine learning classifiers — Random Forest, Naive Bayes, Random Forest with Clustering, and AdaBoost — on a classification task. The project covers the full pipeline from exploratory data analysis (EDA) and preprocessing to model training, evaluation, and visualization.

Features
Data Understanding and Preprocessing:
Comprehensive EDA to analyze data distribution, identify missing values, and prepare data through cleaning, encoding, and feature engineering.

Model Training and Evaluation:
Implementation of 10-fold cross-validation to assess model performance using key metrics such as Accuracy, F1 Score, Precision, and Recall.

Model Comparison:
Comparison of traditional classifiers including ensemble methods (Random Forest and AdaBoost) and simpler classifiers (Naive Bayes).

Visualization:
Bar charts comparing model accuracies and detailed visualization of decision trees generated by different tools (Weka and scikit-learn), as well as AdaBoost’s weak learners.

Results Summary
Model	Accuracy	F1 Score	Precision	Recall	Training Time (s)	Prediction Time (s)
Random Forest	85.34%	0.8536	0.8539	0.8534	18.56	1.32
Naive Bayes	77.73%	0.7782	0.7794	0.7773	0.08	0.52
Random Forest + Clustering	85.62%	0.8564	0.8566	0.8562	16.94	1.05
AdaBoost	82.45%	0.8249	0.8253	0.8245	20.85	0.60

Requirements
Python 3.7 or higher

scikit-learn

pandas

numpy

matplotlib / seaborn (for visualization)

optionally Weka (for decision tree comparison)

Usage
Data Preparation:

Conduct exploratory data analysis (EDA) using provided scripts/notebooks.

Preprocess the data with cleaning, encoding, and feature engineering.

Model Training and Evaluation:

Run model training scripts to perform 10-fold cross-validation on different models.

Review evaluation metrics to compare model performance.

Visualization:

Generate bar charts and decision tree visualizations to interpret results.

Compare decision trees produced by Weka and scikit-learn.

Project Structure
bash
Sao chép
Chỉnh sửa
/data                   # Dataset files
/scripts                # Python scripts for preprocessing, training, evaluation
/notebooks              # Jupyter notebooks for EDA and visualization
/models                 # Saved models and outputs
/visualizations         # Generated charts and tree images
README.md               # Project overview and instructions
Conclusion
This project demonstrates the importance of understanding the data and carefully selecting and evaluating models. While Random Forest with Clustering achieved the best accuracy, Naive Bayes offers speed advantages, and AdaBoost provides a balanced alternative. Both Weka and scikit-learn are suitable for decision tree modeling, with no significant differences found.
